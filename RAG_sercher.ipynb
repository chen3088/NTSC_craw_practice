{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b575b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 參數設定 ===\n",
    "file_path = \"nstc_jobs_full.csv\"\n",
    "model_name = \"all-MiniLM-L6-v2\"\n",
    "chunk_size = 300\n",
    "chunk_overlap = 30\n",
    "encoding_batch_size = 32\n",
    "top_k = 5\n",
    "output_log_path = \"rag_results_log.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7de123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_and_prepare_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.dropna(subset=[\"職缺名稱\", \"發佈日期\", \"連結\", \"詳細內容\"])\n",
    "\n",
    "    texts = [\n",
    "        f\"職缺名稱：{row['職缺名稱']}\\n發佈日期：{row['發佈日期']}\\n詳細內容：\\n{row['詳細內容']}\"\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    metadatas = [\n",
    "        {\"職缺名稱\": row[\"職缺名稱\"], \"連結\": row[\"連結\"]}\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "\n",
    "    return texts, metadatas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c194caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def build_documents(texts, metadatas, chunk_size, chunk_overlap):\n",
    "    docs = [Document(page_content=text, metadata=meta) for text, meta in zip(texts, metadatas)]\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    return splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f72ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "def hybrid_chunking(text, metadata, chunk_size=300, chunk_overlap=30):\n",
    "    # Step 1: 先依據 【標題】或雙換行或條列符號切段\n",
    "    segments = re.split(r\"(?=【[^】]+】)|(?<=\\n)\\d+\\.\\s+|\\n{2,}\", text)\n",
    "\n",
    "    # Step 2: 對每段做長度判斷，如太長則進一步切割\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "    all_chunks = []\n",
    "\n",
    "    for seg in segments:\n",
    "        if len(seg.strip()) == 0:\n",
    "            continue\n",
    "        doc = Document(page_content=seg.strip(), metadata=metadata)\n",
    "        sub_chunks = splitter.split_documents([doc])\n",
    "        all_chunks.extend(sub_chunks)\n",
    "\n",
    "    return all_chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "\n",
    "def sentence_chunking(text, metadata):\n",
    "    \"Split text into sentences when punctuation is clear.\"\n",
    "    import re\n",
    "    sentences = re.split(r'[。.!?]\\s*', text)\n",
    "    return [Document(page_content=s.strip(), metadata=metadata) for s in sentences if s.strip()]\n",
    "\n",
    "def paragraph_chunking(text, metadata):\n",
    "    \"Split text into paragraphs separated by blank lines.\"\n",
    "    paragraphs = [p.strip() for p in text.split('\\n\\n') if p.strip()]\n",
    "    return [Document(page_content=p, metadata=metadata) for p in paragraphs]\n"
   ],
   "id": "sentence_para_chunking"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8eb17894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def build_faiss_index(split_docs, model_name, batch_size=32):\n",
    "    model = SentenceTransformer(model_name)\n",
    "    contents = [doc.page_content for doc in split_docs]\n",
    "    embeddings = model.encode(contents, show_progress_bar=True, batch_size=batch_size)\n",
    "\n",
    "    dim = embeddings.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(np.array(embeddings))\n",
    "\n",
    "    return index, model, split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46c3f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_query(query, top_k, embedding_model, index, indexed_docs):\n",
    "    query_embedding = embedding_model.encode([query])\n",
    "    D, I = index.search(np.array(query_embedding), top_k)\n",
    "\n",
    "    results = []\n",
    "    for i, idx in enumerate(I[0]):\n",
    "        doc = indexed_docs[idx]\n",
    "        snippet = doc.page_content.strip().replace(\"\\n\", \" \")\n",
    "        if len(snippet) > 200:\n",
    "            snippet = snippet[:200] + \"...\"\n",
    "\n",
    "        results.append({\n",
    "            \"query\": query,\n",
    "            \"rank\": i + 1,\n",
    "            \"職缺名稱\": doc.metadata[\"職缺名稱\"],\n",
    "            \"連結\": doc.metadata[\"連結\"],\n",
    "            \"摘要\": snippet\n",
    "        })\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2d388e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def save_rag_log(results, model_name, chunk_size, chunk_overlap, save_path=\"rag_results_log.csv\"):\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    write_header = not os.path.exists(save_path)\n",
    "\n",
    "    with open(save_path, \"a\", newline='', encoding=\"utf-8-sig\") as f:  # 👈 修正編碼為 utf-8-sig\n",
    "        writer = csv.DictWriter(\n",
    "            f,\n",
    "            fieldnames=[\"timestamp\", \"query\", \"rank\", \"職缺名稱\", \"連結\", \"摘要\", \"model_name\", \"chunk_size\", \"chunk_overlap\"]\n",
    "        )\n",
    "        if write_header:\n",
    "            writer.writeheader()\n",
    "        for row in results:\n",
    "            writer.writerow({\n",
    "                \"timestamp\": timestamp,\n",
    "                \"query\": row[\"query\"],\n",
    "                \"rank\": row[\"rank\"],\n",
    "                \"職缺名稱\": row[\"職缺名稱\"],\n",
    "                \"連結\": row[\"連結\"],\n",
    "                \"摘要\": row[\"摘要\"],\n",
    "                \"model_name\": model_name,\n",
    "                \"chunk_size\": chunk_size,\n",
    "                \"chunk_overlap\": chunk_overlap\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ebd91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def save_rag_log_to_excel(results, model_name, chunk_size, chunk_overlap, save_path=\"rag_results_log.xlsx\"):\n",
    "    from datetime import datetime\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    df = pd.DataFrame([{\n",
    "        \"timestamp\": timestamp,\n",
    "        \"query\": row[\"query\"],\n",
    "        \"rank\": row[\"rank\"],\n",
    "        \"職缺名稱\": row[\"職缺名稱\"],\n",
    "        \"連結\": row[\"連結\"],\n",
    "        \"摘要\": row[\"摘要\"],\n",
    "        \"model_name\": model_name,\n",
    "        \"chunk_size\": chunk_size,\n",
    "        \"chunk_overlap\": chunk_overlap\n",
    "    } for row in results])\n",
    "\n",
    "    df.to_excel(save_path, index=False)  # ❗ Excel 不用擔心編碼問題\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "345700e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 48/48 [00:54<00:00,  1.14s/it]\n"
     ]
    }
   ],
   "source": [
    "# 🚀 一次性初始化系統\n",
    "texts, metadatas = load_and_prepare_data(file_path)\n",
    "split_docs = build_documents(texts, metadatas, chunk_size, chunk_overlap)\n",
    "index, embedding_model, indexed_docs = build_faiss_index(split_docs, model_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65c18bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 1. 國立中山大學新海研3號貴重儀器使用中心誠徵專任技術員1名\n",
      "🔗 https://www.nstc.gov.tw/folksonomy/detail/ddc2e921-92c5-4004-8c2f-be2373c53f52?l=ch\n",
      "📝 相關應徵資料予以保密，合者約談，不合者恕不另行通知。 發佈日期：2025-07-04 00:00:00\n",
      "\n",
      "🔎 2. [徵才] 國立臺灣大學防災減害與韌性學程 (綠‧韌性研究室) 徵求都市規劃/景觀/地理資訊專長 [專任計畫助理]\n",
      "🔗 https://www.nstc.gov.tw/folksonomy/detail/2793c7ef-b68d-4f00-9388-e011b78b9553?l=ch\n",
      "📝 3.其他有利申請之相關文件 發佈日期：2025-07-21 00:00:00\n",
      "\n",
      "🔎 3. 中國醫藥大學 癌症生物精準醫學研究中心  王紹椿老師實驗室 誠徵 博士後研究員\n",
      "🔗 https://www.nstc.gov.tw/folksonomy/detail/701ca4f1-a9f5-4a61-9b66-c4cf60f5c093?l=ch\n",
      "📝 歡迎對癌症研究有興趣的夥伴加入我們的團隊！ 發佈日期：2025-07-14 00:00:00\n",
      "\n",
      "🔎 4. 中國醫藥大學 癌症生物精準醫學研究中心  王紹椿老師實驗室 誠徵 碩士級研究助理\n",
      "🔗 https://www.nstc.gov.tw/folksonomy/detail/2521ae27-55c0-4f27-9ded-b4bc908c1aff?l=ch\n",
      "📝 歡迎對癌症研究有興趣的夥伴加入我們的團隊！ 發佈日期：2025-07-14 00:00:00\n",
      "\n",
      "🔎 5. 國立臺東大學通識教育中心徵聘專任助理教授以上教師徵才公告，收件至114年8月15日止。\n",
      "🔗 https://www.nstc.gov.tw/folksonomy/detail/e407fdbc-62c9-4e09-b08a-35a897cc4186?l=ch\n",
      "📝 其    它： 相關訊息，請至本校首頁徵人啟事https://psn.nttu.edu.tw/p/406-1047-165359,r595.php?Lang=zh-tw查詢下載。 聯絡人姓名: 李家婕小姐 聯絡人電話: 089-517492 電子信箱：evalee@nttu.edu.tw 發佈日期：2025-07-09 00:00:00\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 🎯 查詢並儲存紀錄\n",
    "query = \"材料相關的職缺有哪些？\"\n",
    "results = rag_query(query, top_k, embedding_model, index, indexed_docs)\n",
    "save_rag_log(results, model_name, chunk_size, chunk_overlap, save_path=output_log_path)\n",
    "save_rag_log_to_excel(results, model_name, chunk_size, chunk_overlap, save_path=\"rag_results_log.xlsx\")\n",
    "# 👀 顯示查詢結果\n",
    "for r in results:\n",
    "    print(f\"🔎 {r['rank']}. {r['職缺名稱']}\")\n",
    "    print(f\"🔗 {r['連結']}\")\n",
    "    print(f\"📝 {r['摘要']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80f2065a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_documents_hybrid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m docs_recursive \u001b[38;5;241m=\u001b[39m build_documents(texts, metadatas, chunk_size, chunk_overlap)  \u001b[38;5;66;03m# 原法\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m docs_hybrid \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_documents_hybrid\u001b[49m(texts, metadatas, chunk_size, chunk_overlap)  \u001b[38;5;66;03m# 改用 hybrid chunking\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_documents_hybrid' is not defined"
     ]
    }
   ],
   "source": [
    "docs_recursive = build_documents(texts, metadatas, chunk_size, chunk_overlap)  # 原法\n",
    "docs_hybrid = build_documents_hybrid(texts, metadatas, chunk_size, chunk_overlap)  # 改用 hybrid chunking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b31ab79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}